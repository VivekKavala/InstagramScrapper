{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9107920a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Log In Credentials for Instagram\n",
      "Enter Username : unique__username___\n",
      "Enter Password : unique@password\n",
      "Enter the Username or Hashtag to search in Instagram : #ipl2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivek\\AppData\\Local\\Temp\\ipykernel_11908\\1794156258.py:18: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r\"C:/Users/vivek/Desktop/chromedriver_win32/chromedriver.exe\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images ...\n",
      "100% [................................................................................] 5225 / 5225\n",
      "Data is saved at  C:\\ipl2023 Data\n",
      "DO YOU WANT TO TRY AGAIN(Y or N) :y\n",
      "\n",
      "Log In Credentials for Instagram\n",
      "Enter Username : jbdiuf\n",
      "Enter Password : dfiggisdugfigsd\n",
      "Enter the Username or Hashtag to search in Instagram : udfiu\n",
      "Failed To Login To Your Instagram Account !!!,Invalid input credentials or poor internet connection\n",
      "DO YOU WANT TO TRY AGAIN(Y or N) :N\n",
      "\n",
      "Program Terminated !!!\n"
     ]
    }
   ],
   "source": [
    "#python program to automate the process of scrapping data from instagram by logging into your account\n",
    "#importing required libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import time\n",
    "import os\n",
    "import wget\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def search_for_keyword(username,password,keyword):  \n",
    "    global driver\n",
    "    #initializing chrome driver for controling Chrome from program \n",
    "    driver = webdriver.Chrome(r\"C:/Users/vivek/Desktop/chromedriver_win32/chromedriver.exe\")\n",
    "    #maximizing window\n",
    "    driver.maximize_window()\n",
    "    #opening instagram in the Chrome\n",
    "    driver.get('https://www.instagram.com/')\n",
    "    #navigating to username and password fields in the Instagram login page\n",
    "    username_field = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='username']\")))\n",
    "    password_field = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='password']\")))\n",
    "    #clearing the username and password fields\n",
    "    username_field.clear()\n",
    "    password_field.clear()\n",
    "    #passing username and password\n",
    "    username_field.send_keys(username)\n",
    "    password_field.send_keys(password)\n",
    "    #clicking on the log in button\n",
    "    try :\n",
    "        log_in =  WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[type='submit']\"))).click()\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(10)\n",
    "    check = driver.find_element(By.CSS_SELECTOR,'body')\n",
    "    check = check.get_attribute('class')\n",
    "    if check == '_a3wf _-kb segoe':\n",
    "        return \"ERROR-1\"\n",
    "    #cliclking on the Not Now buttons if they appear on the screen \n",
    "    try:\n",
    "        not_now =  WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH , '//button[contains(text(),\"Not Now\")]'))).click()\n",
    "        not_now_2 = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH , '//button[contains(text(),\"Not Now\")]'))).click()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        search = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"div[class='_aacl _aacp _aacu _aacx _aada']\"))).click()\n",
    "        search_box = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH , '//input[@placeholder=\"Search\"]')))\n",
    "    except:\n",
    "        search_box = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH , '//input[@placeholder=\"Search\"]')))\n",
    "    #to clear the search box\n",
    "    search_box.clear()\n",
    "    #to pass the keyword to the search box\n",
    "    search_box.send_keys(keyword)\n",
    "    time.sleep(5)\n",
    "    #to click on the first result that appear after searching a keyword \n",
    "    account_click = driver.find_element(By.CSS_SELECTOR,'div[class=\"_aacl _aaco _aacw _aacx _aad6\"]')\n",
    "    keyword_new = account_click.text\n",
    "    account_click.click()\n",
    "    #to check whether the given keyword is a hashtag or a username\n",
    "    if keyword_new[0] == '#':\n",
    "        #to scrap using the hashtag \n",
    "        scrap_using_hashtag(keyword_new)\n",
    "    else:\n",
    "        #to scrap using the keyword\n",
    "        scrap_using_username(keyword_new)\n",
    "      \n",
    "    \n",
    "def scrap_using_hashtag(keyword_new):\n",
    "    time.sleep(15)\n",
    "    #to find the number of posts for a given hashtag\n",
    "    hashtag_posts = driver.find_element(By.CSS_SELECTOR, 'div[class=\"_aacl _aacp _aacu _aacx _aad6 _aade\"]').text\n",
    "    #for setting the path in the computer to store the output data\n",
    "    path = setting_path(keyword_new[1:])\n",
    "    old_path = path\n",
    "    os.mkdir(path)\n",
    "    path = os.path.join(path, keyword_new + ' Hashtag Images')\n",
    "    os.mkdir(path)\n",
    "    #scrolling the webpage using the javascript method\n",
    "    driver.execute_script('window.scrollTo(0,10000);')\n",
    "    #finding the elements in the webpage with the img tag name\n",
    "    images = driver.find_elements(By.CSS_SELECTOR, 'img')\n",
    "    images = [image.get_attribute('src') for image in images]\n",
    "    counter = 0\n",
    "    print(\"Downloading Images ...\")\n",
    "    for image in images:\n",
    "        save_as = os.path.join(path, keyword_new + \" Image \" + str(counter+1) + \".jpg\")\n",
    "        #to download the images that are selected \n",
    "        wget.download(image, save_as)\n",
    "        counter += 1\n",
    "    print(\"\\nData is saved at \",old_path)\n",
    "    \n",
    "def scrap_using_username(keyword_new):\n",
    "    time.sleep(10)\n",
    "    #to get the user profile details from the page\n",
    "    user_info = driver.find_elements(By.CSS_SELECTOR, \"div[class='_aacl _aacp _aacu _aacx _aad6 _aade']\")\n",
    "    user_info_new = [user.text for user in user_info]\n",
    "    user_posts = user_info_new[0]\n",
    "    user_followers = user_info_new[1]\n",
    "    user_following = user_info_new[2]\n",
    "    user_bio = user_info_new[3]\n",
    "    user_username = keyword_new\n",
    "    try:\n",
    "        external_links = driver.find_element(By.CSS_SELECTOR, \"div[class='_aacl _aacp _aacw _aacz _aada _aade']\").text\n",
    "    except:\n",
    "        external_links = \"None\"\n",
    "    path = setting_path(keyword_new)\n",
    "    old_path = path\n",
    "    os.mkdir(path)\n",
    "    #storing the data in a dictionary\n",
    "    dictionary = {\n",
    "        \"Username\": user_username,\n",
    "        \"Posts\": user_posts,\n",
    "        \"Followers\": user_followers,\n",
    "        \"Follwing\":user_following,\n",
    "        \"Bio\":user_bio,\n",
    "        \"External links in profile\":external_links\n",
    "    }\n",
    " \n",
    "    # Serializing json\n",
    "    json_object = json.dumps(dictionary, indent=6)\n",
    " \n",
    "    # Writing to sample.json\n",
    "    file_name = path + \"\\\\\" + keyword_new + \" account info.json\"\n",
    "    with open(file_name, \"w\") as outfile:\n",
    "        outfile.write(json_object)\n",
    "        \n",
    "    #clicking on followers \n",
    "    followers = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH , \"//div[contains(text(),'followers')]\"))).click()\n",
    "    time.sleep(5)\n",
    "    driver.execute_script(\"window.scrollTo(0,4000);\")\n",
    "    #getting the usernames of the followers\n",
    "    followers_usernames = driver.find_elements(By.CSS_SELECTOR, \"div[class=' _ab8y  _ab94 _ab97 _ab9f _ab9k _ab9p _abcm']\")\n",
    "    time.sleep(30)\n",
    "    followers_usernames = [follower_username.text for follower_username in followers_usernames]\n",
    "    d1 = {\"Usernames\":followers_usernames}\n",
    "    #converting into a dataframe\n",
    "    df = pd.DataFrame(d1)\n",
    "    df.index += 1\n",
    "    #data is stored in a csv file\n",
    "    csv_file = df.to_csv()\n",
    "    file_name_followers = path + \"\\\\\" + keyword_new + \" Followers Usernames.csv\"\n",
    "    with open(file_name_followers,'w') as follow_file:\n",
    "        follow_file.write(csv_file)\n",
    "    #clicking on the cancel button that appear on the folowers page\n",
    "    cancel = WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'div[class=\"_ab8w  _ab94 _ab99 _ab9f _ab9m _ab9p  _ab9y _abcm\"]'))).click()\n",
    "    \n",
    "    time.sleep(5)\n",
    "    #clicking on following\n",
    "    following = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH , \"//div[contains(text(),'following')]\"))).click()\n",
    "    time.sleep(5)\n",
    "    driver.execute_script(\"window.scrollTo(0,10000);\")\n",
    "    #to extract the usernames of the following members\n",
    "    following_usernames = driver.find_elements(By.CSS_SELECTOR, \"div[class=' _ab8y  _ab94 _ab97 _ab9f _ab9k _ab9p _abcm']\") \n",
    "    time.sleep(20)\n",
    "    following_usernames = [following_username.text for following_username in following_usernames]\n",
    "    d1 = {\"Usernames\":following_usernames}\n",
    "    #converting into dataframe\n",
    "    df = pd.DataFrame(d1)\n",
    "    df.index += 1\n",
    "    csv_file = df.to_csv()\n",
    "    file_name_following = path + \"\\\\\" + keyword_new + \" Following Usernames.csv\"\n",
    "    with open(file_name_following,'w') as following_file:\n",
    "        following_file.write(csv_file)\n",
    "    #clicking on the cancel button on the following page\n",
    "    cancel = WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'div[class=\"_ab8w  _ab94 _ab99 _ab9f _ab9m _ab9p  _ab9y _abcm\"]'))).click()\n",
    "    \n",
    "    time.sleep(5)\n",
    "    #setting path to store the images\n",
    "    path = os.path.join(path, keyword_new + ' account Images')\n",
    "    os.mkdir(path)\n",
    "    driver.execute_script('window.scrollTo(0,10000);')\n",
    "    images = driver.find_elements(By.CSS_SELECTOR, 'img')\n",
    "    images = [image.get_attribute('src') for image in images]\n",
    "    length = len(images)\n",
    "    counter = 0\n",
    "    print(\"Downloading Images ...\")\n",
    "    for image in images:\n",
    "        if counter != (length-1):\n",
    "            save_as = os.path.join(path, keyword_new + \" Image \" + str(counter+1) + \".jpg\")\n",
    "            #to download the images using their the url\n",
    "            wget.download(image, save_as)\n",
    "        counter += 1\n",
    "    print(\"\\nData is saved at \",old_path)\n",
    "        \n",
    "def setting_path(keyword_new):\n",
    "    path = 'C:\\\\'\n",
    "    path = os.path.join(path, keyword_new + \" Data\")\n",
    "    return path\n",
    "\n",
    "def log_in_credentials():\n",
    "    print(\"\\nLog In Credentials for Instagram\")\n",
    "    #for taking username as a input from the user\n",
    "    username = input(\"Enter Username : \")\n",
    "    #password from the user\n",
    "    password = input(\"Enter Password : \")\n",
    "    #keyword to search for\n",
    "    keyword = input(\"Enter the Username or Hashtag to search in Instagram : \")\n",
    "    result = search_for_keyword(username,password,keyword)\n",
    "    check_status(result)\n",
    "\n",
    "def check_status(result):\n",
    "    #if the credentials entered by the user are incorrect\n",
    "    if result == \"ERROR-1\":\n",
    "        print(\"Failed To Login To Your Instagram Account !!!,Invalid input credentials or poor internet connection\")\n",
    "        try_again_status = input(\"DO YOU WANT TO TRY AGAIN(Y or N) :\")\n",
    "        #want to try again or not\n",
    "        if try_again_status.upper() == 'Y': \n",
    "            log_in_credentials()\n",
    "        else:\n",
    "            print(\"\\nProgram Terminated !!!\")\n",
    "            pass\n",
    "    else:\n",
    "        try_again_status = input(\"DO YOU WANT TO TRY AGAIN(Y or N) :\")\n",
    "        #want to try again or not\n",
    "        if try_again_status.upper() == 'Y': \n",
    "            log_in_credentials()\n",
    "        else:\n",
    "            print(\"\\nProgram Terminated !!!\")\n",
    "            pass\n",
    "log_in_credentials()\n",
    "#code by vivek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d4b5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929d0003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b0563e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcff37c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "6170bf5035867d6a01f2a3c79f9a5631c5aafb800579911d8223195b30c4ad84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
